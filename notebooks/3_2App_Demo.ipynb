{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e4b65b",
   "metadata": {},
   "source": [
    "# Lab 02: Handwritten Digit Recognition App\n",
    "\n",
    "**Group 09** \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "This notebook serves as the final application interface. It allows users to:\n",
    "1.  **Upload** an image of a handwritten digit (or use sample images).\n",
    "2.  **Process** the image (grayscale, resize, feature extraction).\n",
    "3.  **Predict** the digit using our best trained Softmax Regression model.\n",
    "4.  **Visualize** the prediction confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5441bf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully from ../models/best_model_weights.npz\n",
      "   - Weights Shape: (81, 10)\n",
      "   - Bias Shape: (1, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# --- SOFTMAX REGRESSION CLASS (Inference Only) ---\n",
    "class SoftmaxRegression:\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "\n",
    "    def softmax(self, z):\n",
    "        z_stable = z - np.max(z, axis=1, keepdims=True)\n",
    "        exp_z = np.exp(z_stable)\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        z = np.dot(X, self.W) + self.b\n",
    "        return self.softmax(z)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "    def load_weights(self, filepath):\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"❌ Error: Weight file not found at {filepath}\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            data = np.load(filepath)\n",
    "            self.W = data['W']\n",
    "            self.b = data['b']\n",
    "            print(f\"✅ Model loaded successfully from {filepath}\")\n",
    "            print(f\"   - Weights Shape: {self.W.shape}\")\n",
    "            print(f\"   - Bias Shape: {self.b.shape}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading weights: {e}\")\n",
    "            return False\n",
    "\n",
    "# Initialize and Load\n",
    "model = SoftmaxRegression()\n",
    "weight_path = \"../models/best_model_weights.npz\"\n",
    "model_ready = model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3ddc30",
   "metadata": {},
   "source": [
    "## 2. Smart Feature Pipeline\n",
    "\n",
    "Since we experimented with different features (Raw, Deskewed, HOG), the application must define which processing pipeline to use based on the loaded model's input dimension ($D$).\n",
    "\n",
    "* **If $D = 784$:** The model uses Pixels. We will apply **Deskewing** + **Normalization** to give it the best chance (as Deskewing improves raw pixel models).\n",
    "* **If $D = 81$:** The model uses **HOG**. We will compute HOG features.\n",
    "* **Other:** Fallback to raw resizing (or error if PCA was used without saved components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc8a11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. DESKEWING FUNCTION ---\n",
    "def deskew_image(img):\n",
    "    \"\"\"Straightens the digit.\"\"\"\n",
    "    m = cv2.moments(img)\n",
    "    if abs(m['mu02']) < 1e-2: return img.copy()\n",
    "    skew = m['mu11'] / m['mu02']\n",
    "    M = np.float32([[1, skew, -0.5*28*skew], [0, 1, 0]])\n",
    "    return cv2.warpAffine(img, M, (28, 28), flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n",
    "\n",
    "# --- 2. HOG FUNCTION ---\n",
    "def extract_hog_feature(img):\n",
    "    \"\"\"Extracts 81 HOG features from a single image.\"\"\"\n",
    "    # Ensure params match training\n",
    "    hog = cv2.HOGDescriptor(_winSize=(28, 28), _blockSize=(14, 14), _blockStride=(7, 7), _cellSize=(14, 14), _nbins=9)\n",
    "    # HOG needs uint8\n",
    "    img_uint8 = (img * 255).astype(np.uint8) if img.max() <= 1.0 else img.astype(np.uint8)\n",
    "    return hog.compute(img_uint8).flatten()\n",
    "\n",
    "# --- 3. MASTER PREPROCESSOR ---\n",
    "def process_input(image_pil, model_input_dim):\n",
    "    \"\"\"\n",
    "    Converts PIL image to model input vector based on dimension.\n",
    "    \"\"\"\n",
    "    # A. Basic Processing (Grayscale -> Resize -> Invert -> Numpy)\n",
    "    img = image_pil.convert('L')\n",
    "    img = img.resize((28, 28), Image.Resampling.LANCZOS)\n",
    "    img_arr = np.array(img)\n",
    "    \n",
    "    # Invert if background is white (common in drawing apps/paper)\n",
    "    if np.mean(img_arr) > 128:\n",
    "        img_arr = 255 - img_arr\n",
    "    \n",
    "    # Normalize to 0-1 float for deskewing/raw\n",
    "    img_norm = img_arr.astype(np.float32) / 255.0\n",
    "    \n",
    "    # B. Branch based on Model Dimension\n",
    "    \n",
    "    # Case 1: HOG Model (81 features)\n",
    "    if model_input_dim == 81:\n",
    "        # HOG handles its own normalization, pass the deskewed version for better results?\n",
    "        # Let's just pass the basic one to match training pipeline usually.\n",
    "        # But deskewing helps HOG too. Let's apply Deskew -> HOG\n",
    "        img_deskew = deskew_image((img_norm * 255).astype(np.uint8))\n",
    "        features = extract_hog_feature(img_deskew)\n",
    "        return img_arr, img_deskew, features.reshape(1, -1), \"HOG (81)\"\n",
    "        \n",
    "    # Case 2: Pixel Model (784 features)\n",
    "    elif model_input_dim == 784:\n",
    "        # Always Apply Deskewing for best performance on 784 models\n",
    "        img_deskew = deskew_image((img_norm * 255).astype(np.uint8))\n",
    "        img_final = img_deskew.astype(np.float32) / 255.0\n",
    "        return img_arr, img_deskew, img_final.reshape(1, -1), \"Deskewed Pixels (784)\"\n",
    "    \n",
    "    # Case 3: PCA or others (Not supported in simple demo without saving components)\n",
    "    else:\n",
    "        return img_arr, img_arr, None, f\"Unsupported Dim: {model_input_dim}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4807c23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f657483f80a4a1390f0ce7f1db77b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>✍️ Handwritten Digit Recognizer</h3>'), HBox(children=(FileUpload(value=(), acc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- WIDGET UI ---\n",
    "\n",
    "# 1. Widgets\n",
    "uploader = widgets.FileUpload(accept='image/*', multiple=False, description='Upload Digit')\n",
    "btn_predict = widgets.Button(description='Predict', button_style='primary', icon='magic')\n",
    "out_display = widgets.Output()\n",
    "\n",
    "def on_click_predict(b):\n",
    "    out_display.clear_output()\n",
    "    \n",
    "    if not model_ready:\n",
    "        with out_display: print(\"❌ Model not loaded. Run Notebook 2 first.\")\n",
    "        return\n",
    "        \n",
    "    if not uploader.value:\n",
    "        with out_display: print(\"⚠️ Please upload an image first.\")\n",
    "        return\n",
    "\n",
    "    # Load Image\n",
    "    try:\n",
    "        # Handle different ipywidgets versions\n",
    "        file_info = uploader.value[0] if isinstance(uploader.value, tuple) else uploader.value\n",
    "        # Access 'content' key safely\n",
    "        if isinstance(file_info, dict):\n",
    "            content = file_info.get('content')\n",
    "            if content is None: # Sometimes it's nested differently\n",
    "                 content = list(file_info.values())[0]['content']\n",
    "        else: # List of dicts\n",
    "             content = file_info[0]['content']\n",
    "             \n",
    "        img_pil = Image.open(BytesIO(content))\n",
    "    except Exception as e:\n",
    "        with out_display: print(f\"Error reading file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Process\n",
    "    input_dim = model.W.shape[0]\n",
    "    img_orig, img_processed, X_input, method_name = process_input(img_pil, input_dim)\n",
    "    \n",
    "    if X_input is None:\n",
    "        with out_display: print(f\"❌ Error: {method_name}. Need PCA components file to run PCA models.\")\n",
    "        return\n",
    "\n",
    "    # Predict\n",
    "    probs = model.predict_proba(X_input)[0]\n",
    "    pred_label = np.argmax(probs)\n",
    "    confidence = probs[pred_label]\n",
    "\n",
    "    # Visualize\n",
    "    with out_display:\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        \n",
    "        # 1. Original\n",
    "        ax[0].imshow(img_orig, cmap='gray')\n",
    "        ax[0].set_title(\"Original Input\")\n",
    "        ax[0].axis('off')\n",
    "        \n",
    "        # 2. Processed (What model sees)\n",
    "        ax[1].imshow(img_processed, cmap='gray')\n",
    "        ax[1].set_title(f\"Processed: {method_name}\")\n",
    "        ax[1].axis('off')\n",
    "        \n",
    "        # 3. Bar Chart\n",
    "        bars = ax[2].bar(range(10), probs, color='skyblue')\n",
    "        bars[pred_label].set_color('orange')\n",
    "        ax[2].set_xticks(range(10))\n",
    "        ax[2].set_title(f\"Prediction: {pred_label} ({confidence:.1%})\")\n",
    "        ax[2].set_ylim(0, 1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "btn_predict.on_click(on_click_predict)\n",
    "\n",
    "# Layout\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>✍️ Handwritten Digit Recognizer</h3>\"),\n",
    "    widgets.HBox([uploader, btn_predict]),\n",
    "    out_display\n",
    "]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
