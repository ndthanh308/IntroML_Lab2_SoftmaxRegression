# MNIST Digit Recognition with Softmax Regression

ğŸ”¢ **Nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay MNIST sá»­ dá»¥ng Softmax Regression vÃ  Feature Engineering**

---

## ğŸ“– MÃ´ táº£ BÃ i toÃ¡n

Dá»± Ã¡n nÃ y thá»±c hiá»‡n **nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay** (0-9) tá»« bá»™ dá»¯ liá»‡u MNIST báº±ng mÃ´ hÃ¬nh **Softmax Regression** Ä‘Æ°á»£c láº­p trÃ¬nh tá»« Ä‘áº§u (from scratch) chá»‰ sá»­ dá»¥ng **NumPy**. 

### Má»¥c tiÃªu chÃ­nh:
1. **XÃ¢y dá»±ng Softmax Regression tá»« Ä‘áº§u** (khÃ´ng dÃ¹ng thÆ° viá»‡n há»c mÃ¡y nhÆ° scikit-learn, TensorFlow, PyTorch)
2. **NghiÃªn cá»©u cÃ¡c phÆ°Æ¡ng phÃ¡p Feature Engineering** Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c
3. **So sÃ¡nh hiá»‡u suáº¥t** giá»¯a 5 phÆ°Æ¡ng phÃ¡p biáº¿n Ä‘á»•i Ä‘áº·c trÆ°ng khÃ¡c nhau
4. **Triá»ƒn khai á»©ng dá»¥ng web** cho ngÆ°á»i dÃ¹ng cuá»‘i sá»­ dá»¥ng Streamlit

### Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c:
- âœ… **Äá»™ chÃ­nh xÃ¡c cao nháº¥t: 92.49%** (PCA 256 components)
- âœ… **5 phÆ°Æ¡ng phÃ¡p Feature Engineering** Ä‘Æ°á»£c thá»±c nghiá»‡m vÃ  Ä‘Ã¡nh giÃ¡
- âœ… **á»¨ng dá»¥ng web tÆ°Æ¡ng tÃ¡c** cho phÃ©p váº½ chá»¯ sá»‘ hoáº·c táº£i áº£nh tá»« file
- âœ… **TÃ i liá»‡u chi tiáº¿t** vá»›i phÃ¢n tÃ­ch toÃ¡n há»c vÃ  trá»±c quan hÃ³a

---

## ğŸ‘¥ ThÃ´ng tin NhÃ³m

**Group 09**

| STT | Há» vÃ  TÃªn | MSSV | CÃ´ng viá»‡c chÃ­nh |
|-----|-----------|------|-----------------|
| 1   | **BÃ¹i Huy GiÃ¡p** | 23127289 | Dáº«n xuáº¥t cÃ´ng thá»©c Softmax & Cross-entropy; CÃ i Ä‘áº·t mÃ´ hÃ¬nh Softmax Regression; Feature Engineering: PCA & Rotation Invariance; Tá»•ng há»£p bÃ¡o cÃ¡o cuá»‘i |
| 2   | **LÃª Minh Äá»©c** | 23127351 | Feature Engineering: Sobel Edge Detection; Viáº¿t cÃ¡c hÃ m metrics (Accuracy, Precision, Recall, F1-score); Viáº¿t bÃ¡o cÃ¡o |
| 3   | **VÅ© Tiáº¿n DÅ©ng** | 23127354 | Feature Engineering: Baseline; Tá»•ng há»£p Metrics vÃ  so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh; Viáº¿t bÃ¡o cÃ¡o |
| 4   | **Äinh XuÃ¢n KhÆ°Æ¡ng** | 23127398 | Feature Engineering: Average Pooling; XÃ¢y dá»±ng á»©ng dá»¥ng Streamlit nháº­n dáº¡ng chá»¯ sá»‘; Viáº¿t bÃ¡o cÃ¡o |
| 5   | **Nguyá»…n Äá»“ng Thanh** | 23127538 | Dáº«n xuáº¥t cÃ´ng thá»©c Gradient Descent; Táº¡o framework trÃ¬nh bÃ y Feature Vector; Tiá»n xá»­ lÃ½ dá»¯ liá»‡u MNIST; Chuáº©n bá»‹ submission files; Quay video demo; Tá»•ng há»£p bÃ¡o cÃ¡o cuá»‘i |

**MÃ´n há»c**: Nháº­p mÃ´n Há»c mÃ¡y (Introduction to Machine Learning)  
**Giáº£ng viÃªn**: Tháº§y BÃ¹i Tiáº¿n LÃªn, Tháº§y LÃª Nhá»±t Nam, Tháº§y VÃµ Nháº­t TÃ¢n
**Há»c ká»³**: HK1 2025-2026

---

## ğŸ“‚ Cáº¥u trÃºc ThÆ° má»¥c

```
IntroML_Lab2_SoftmaxRegression/
â”‚
â”œâ”€â”€ ğŸ“„ App_demo.py                    # á»¨ng dá»¥ng Streamlit triá»ƒn khai mÃ´ hÃ¬nh
â”œâ”€â”€ ğŸ“„ requirements.txt               # Danh sÃ¡ch thÆ° viá»‡n cáº§n thiáº¿t
â”œâ”€â”€ ğŸ“„ README.md                      # TÃ i liá»‡u nÃ y
â”œâ”€â”€ ğŸ“„ LICENSE                        # Giáº¥y phÃ©p mÃ£ nguá»“n
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ ğŸ“ raw/
â”‚       â””â”€â”€ ğŸ“„ mnist.npz              # Dá»¯ liá»‡u MNIST (tá»± Ä‘á»™ng táº£i vá» khi cháº¡y láº§n Ä‘áº§u)
â”‚
â”œâ”€â”€ ğŸ“ lib/
â”‚   â”œâ”€â”€ ğŸ“„ SoftmaxRegression.py       # Class mÃ´ hÃ¬nh Softmax Regression
â”‚   â””â”€â”€ ğŸ“„ helpers.py                 # CÃ¡c hÃ m tiá»‡n Ã­ch (load data, metrics, visualization)
â”‚
â”œâ”€â”€ ğŸ“ models/
â”‚   â””â”€â”€ ğŸ“„ best_model_weights.npz     # Trá»ng sá»‘ mÃ´ hÃ¬nh tá»‘t nháº¥t (PCA 256, accuracy: 92.78%)
â”‚
â””â”€â”€ ğŸ“ notebooks/
    â”œâ”€â”€ ğŸ““ 1_Implementation.ipynb           # Notebook 1: CÃ i Ä‘áº·t Softmax Regression cÆ¡ báº£n
    â””â”€â”€ ğŸ““ 2_Feature_Experiments.ipynb      # Notebook 2: Thá»±c nghiá»‡m 5 phÆ°Æ¡ng phÃ¡p Feature Engineering
```

### Chi tiáº¿t cÃ¡c file quan trá»ng:

#### 1. **`lib/SoftmaxRegression.py`**
Chá»©a class `SoftmaxRegression` vá»›i cÃ¡c phÆ°Æ¡ng thá»©c:
- `__init__()`: Khá»Ÿi táº¡o trá»ng sá»‘ W vÃ  bias b
- `softmax()`: HÃ m kÃ­ch hoáº¡t Softmax cÃ³ á»•n Ä‘á»‹nh sá»‘ há»c
- `forward()`: Lan truyá»n xuÃ´i (Z = XW + b)
- `compute_loss()`: TÃ­nh Cross-Entropy Loss
- `backward()`: TÃ­nh gradient (Ä‘áº¡o hÃ m) cá»§a W vÃ  b
- `fit()`: Huáº¥n luyá»‡n mÃ´ hÃ¬nh báº±ng Mini-batch Gradient Descent
- `predict()`: Dá»± Ä‘oÃ¡n nhÃ£n (argmax)
- `predict_proba()`: Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t cÃ¡c lá»›p
- `save_weights()` / `load_weights()`: LÆ°u/Ä‘á»c trá»ng sá»‘ mÃ´ hÃ¬nh

#### 2. **`lib/helpers.py`**
CÃ¡c hÃ m há»— trá»£:
- `load_mnist_data()`: Táº£i vÃ  tiá»n xá»­ lÃ½ MNIST (tá»± Ä‘á»™ng táº£i náº¿u chÆ°a cÃ³)
- `one_hot_encode()`: MÃ£ hÃ³a one-hot cho nhÃ£n
- `compute_confusion_matrix()`: TÃ­nh ma tráº­n nháº§m láº«n
- `compute_metrics()`: TÃ­nh Accuracy, Precision, Recall, F1-Score
- `plot_confusion_matrix()`: Váº½ heatmap ma tráº­n nháº§m láº«n
- `plot_loss_curve()`: Váº½ Ä‘á»“ thá»‹ Loss qua cÃ¡c epoch

#### 3. **`notebooks/1_Implementation.ipynb`**
**Ná»™i dung**:
- LÃ½ thuyáº¿t Softmax Regression (cÃ´ng thá»©c toÃ¡n há»c)
- CÃ i Ä‘áº·t tá»« Ä‘áº§u (Forward, Backward, Gradient Descent)
- Huáº¥n luyá»‡n trÃªn MNIST baseline (784 features)
- ÄÃ¡nh giÃ¡: Accuracy, Confusion Matrix, Loss Curve
- **Káº¿t quáº£**: 92.07% accuracy, 12.88s training time

#### 4. **`notebooks/2_Feature_Experiments.ipynb`**
**Ná»™i dung**: Thá»±c nghiá»‡m 5 phÆ°Æ¡ng phÃ¡p biáº¿n Ä‘á»•i Ä‘áº·c trÆ°ng:

| PhÆ°Æ¡ng phÃ¡p | Sá»‘ features | Accuracy | Training Time | Äáº·c Ä‘iá»ƒm |
|-------------|-------------|----------|---------------|----------|
| **Baseline** | 784 | 92.07% | 12.88s | Flatten áº£nh 28Ã—28 trá»±c tiáº¿p |
| **Pooling** (pool=2) | 196 | 92.59% | 20.45s | Average pooling 2Ã—2, giá»¯ cáº¥u trÃºc khÃ´ng gian |
| **Sobel** | 784 | 90.06% | 36.82s | PhÃ¡t hiá»‡n biÃªn (edge detection) |
| **PCA** (n=256) | 256 | **92.78%** | 26.62s | **Giáº£m chiá»u dá»¯ liá»‡u, 97.48% variance** âœ¨ |
| **Rotation** | 784 | 81.05% | 54.21s | CÄƒn chá»‰nh theo trá»¥c chÃ­nh |

**Káº¿t luáº­n**: **PCA 256 components** Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t (92.78%) vÃ  Ä‘Æ°á»£c lÆ°u vÃ o `models/best_model_weights.npz`.

#### 5. **`App_demo.py`**
á»¨ng dá»¥ng Streamlit vá»›i 3 chá»©c nÄƒng:
- **Tab 1**: Váº½ chá»¯ sá»‘ báº±ng chuá»™t trÃªn canvas
- **Tab 2**: Táº£i áº£nh chá»¯ sá»‘ tá»« file (JPG, PNG)
- **Tab 3**: Demo vá»›i 10,000 áº£nh tá»« MNIST test set

**TÃ­nh nÄƒng**:
- Hiá»ƒn thá»‹ xÃ¡c suáº¥t dá»± Ä‘oÃ¡n cho 10 chá»¯ sá»‘ (0-9)
- Biá»ƒu Ä‘á»“ thanh (bar chart) cho top-3 dá»± Ä‘oÃ¡n
- Hiá»ƒn thá»‹ áº£nh sau tiá»n xá»­ lÃ½ (28Ã—28 grayscale)
- Sá»­ dá»¥ng mÃ´ hÃ¬nh PCA 256 Ä‘Ã£ huáº¥n luyá»‡n

#### 6. **`models/best_model_weights.npz`**
File chá»©a trá»ng sá»‘ mÃ´ hÃ¬nh tá»‘t nháº¥t:
- `pca_mean`: Vector trung bÃ¬nh cá»§a dá»¯ liá»‡u training (Ä‘á»ƒ chuáº©n hÃ³a)
- `pca_vt`: Ma tráº­n chiáº¿u PCA (256Ã—784)
- `pca_n_components`: 256
- `pca_explained_variance`: Tá»· lá»‡ phÆ°Æ¡ng sai giá»¯ láº¡i (97.48%)
- `model_weights`: W (256Ã—10)
- `model_bias`: b (1Ã—10)
- `scaler_min`, `scaler_max`: GiÃ¡ trá»‹ min/max cho chuáº©n hÃ³a [0, 1]

---

## ğŸ”§ requirements.txt - Chi tiáº¿t

File `requirements.txt` liá»‡t kÃª **9 thÆ° viá»‡n Python** cáº§n thiáº¿t Ä‘á»ƒ cháº¡y dá»± Ã¡n:

```txt
numpy                      # ThÆ° viá»‡n tÃ­nh toÃ¡n ma tráº­n vÃ  vector (CORE)
pandas                     # Xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u dáº¡ng báº£ng
matplotlib                 # Váº½ Ä‘á»“ thá»‹, biá»ƒu Ä‘á»“ (Loss curve, confusion matrix)
opencv-python              # Xá»­ lÃ½ áº£nh (Sobel edge detection)
seaborn                    # Váº½ heatmap Ä‘áº¹p cho confusion matrix
ipywidgets                 # Widget tÆ°Æ¡ng tÃ¡c trong Jupyter Notebook
streamlit                  # Framework táº¡o á»©ng dá»¥ng web
streamlit-drawable-canvas  # Component váº½ trÃªn canvas trong Streamlit
pillow                     # Xá»­ lÃ½ vÃ  chuyá»ƒn Ä‘á»•i áº£nh (PIL)
```

### Giáº£i thÃ­ch tá»«ng thÆ° viá»‡n:

| ThÆ° viá»‡n | Vai trÃ² | Sá»­ dá»¥ng trong dá»± Ã¡n |
|----------|---------|---------------------|
| **numpy** | TÃ­nh toÃ¡n ma tráº­n, vector, Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh | XÃ¢y dá»±ng Softmax Regression (forward, backward, gradient descent), PCA transformation |
| **pandas** | Xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng báº£ng (DataFrame) | Tá»• chá»©c káº¿t quáº£ thá»±c nghiá»‡m, báº£ng so sÃ¡nh metrics |
| **matplotlib** | Váº½ Ä‘á»“ thá»‹ 2D (line plot, bar chart, heatmap) | Váº½ Loss curve, confusion matrix, biá»ƒu Ä‘á»“ so sÃ¡nh |
| **opencv-python** | Xá»­ lÃ½ áº£nh (filter, edge detection, morphology) | Ãp dá»¥ng Sobel filter Ä‘á»ƒ phÃ¡t hiá»‡n biÃªn trong Feature Engineering |
| **seaborn** | Váº½ biá»ƒu Ä‘á»“ thá»‘ng kÃª Ä‘áº¹p (built on matplotlib) | Váº½ heatmap confusion matrix vá»›i mÃ u sáº¯c chuyÃªn nghiá»‡p |
| **ipywidgets** | Táº¡o widget tÆ°Æ¡ng tÃ¡c trong Jupyter (slider, button) | Táº¡o giao diá»‡n tÆ°Æ¡ng tÃ¡c Ä‘á»ƒ chá»n hyperparameters trong notebook |
| **streamlit** | Framework táº¡o á»©ng dá»¥ng web nhanh chÃ³ng | XÃ¢y dá»±ng App_demo.py vá»›i giao diá»‡n Ä‘áº¹p vÃ  tÆ°Æ¡ng tÃ¡c |
| **streamlit-drawable-canvas** | Component váº½ canvas trong Streamlit | Cho phÃ©p ngÆ°á»i dÃ¹ng váº½ chá»¯ sá»‘ báº±ng chuá»™t trÃªn web |
| **pillow** | Xá»­ lÃ½ áº£nh (load, resize, convert format) | Äá»c áº£nh tá»« file upload, chuyá»ƒn Ä‘á»•i sang numpy array |

---

## ğŸš€ HÆ°á»›ng dáº«n CÃ i Ä‘áº·t vÃ  Cháº¡y

### BÆ°á»›c 1: Clone Repository

```bash
git clone https://github.com/[username]/IntroML_Lab2_SoftmaxRegression.git
cd IntroML_Lab2_SoftmaxRegression
```

### BÆ°á»›c 2: Táº¡o Virtual Environment (Khuyáº¿n nghá»‹)

**Windows (PowerShell)**:
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

**Linux/MacOS**:
```bash
python3 -m venv venv
source venv/bin/activate
```

### BÆ°á»›c 3: CÃ i Ä‘áº·t ThÆ° viá»‡n

```bash
pip install -r requirements.txt
```

> **LÆ°u Ã½**: Náº¿u gáº·p lá»—i vá»›i `opencv-python`, thá»­ cÃ i Ä‘áº·t:
> ```bash
> pip install opencv-python-headless
> ```

### BÆ°á»›c 4: Cháº¡y Jupyter Notebooks

#### Option 1: Jupyter Notebook (Classic)
```bash
jupyter notebook
```
Sau Ä‘Ã³ má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p:
- `notebooks/1_Implementation.ipynb` - CÃ i Ä‘áº·t cÆ¡ báº£n
- `notebooks/2_Feature_Experiments.ipynb` - Thá»±c nghiá»‡m Feature Engineering

#### Option 2: Jupyter Lab (Modern)
```bash
jupyter lab
```

#### Option 3: VS Code
- Má»Ÿ file `.ipynb` trong VS Code
- Chá»n kernel Python (tá»« venv Ä‘Ã£ táº¡o)
- Cháº¡y tá»«ng cell báº±ng Shift+Enter

### BÆ°á»›c 5: Cháº¡y á»¨ng dá»¥ng Streamlit

```bash
streamlit run App_demo.py
```

Hoáº·c chá»‰ Ä‘á»‹nh port cá»¥ thá»ƒ:
```bash
streamlit run App_demo.py --server.port 8501
```

á»¨ng dá»¥ng sáº½ má»Ÿ táº¡i: **http://localhost:8501**

### BÆ°á»›c 6: Sá»­ dá»¥ng á»¨ng dá»¥ng

1. **Tab "Váº½ Chá»¯ Sá»‘"**: 
   - Váº½ chá»¯ sá»‘ báº±ng chuá»™t trÃªn canvas tráº¯ng
   - Nháº¥n nÃºt "Dá»± Ä‘oÃ¡n" Ä‘á»ƒ nháº­n káº¿t quáº£
   - Xem xÃ¡c suáº¥t dá»± Ä‘oÃ¡n cho 10 chá»¯ sá»‘

2. **Tab "Táº£i áº¢nh"**:
   - Upload áº£nh chá»¯ sá»‘ (JPG, PNG, etc.)
   - Há»‡ thá»‘ng tá»± Ä‘á»™ng tiá»n xá»­ lÃ½ (resize, grayscale, normalize)
   - Hiá»ƒn thá»‹ dá»± Ä‘oÃ¡n vá»›i Ä‘á»™ tin cáº­y

3. **Tab "MNIST Demo"**:
   - Xem 10,000 áº£nh tá»« MNIST test set
   - Äiá»u chá»‰nh slider Ä‘á»ƒ chá»n áº£nh
   - Xem dá»± Ä‘oÃ¡n vÃ  nhÃ£n thá»±c táº¿

---

## ğŸ“Š Káº¿t quáº£ Thá»±c nghiá»‡m

### So sÃ¡nh 5 PhÆ°Æ¡ng phÃ¡p Feature Engineering:

| PhÆ°Æ¡ng phÃ¡p | Features | Accuracy (%) | Precision (%) | Recall (%) | F1-Score (%) | Training Time (s) | Efficiency Ratio* |
|-------------|----------|--------------|---------------|------------|--------------|-------------------|-------------------|
| **Baseline** | 784 | 92.07 | 92.17 | 92.07 | 92.06 | 12.88 | 0.0715 |
| **Pooling (2Ã—2)** | 196 | 92.59 | 92.68 | 92.59 | 92.59 | 20.45 | **0.0453** |
| **Sobel Edge** | 784 | 90.06 | 90.23 | 90.06 | 90.03 | 36.82 | 0.0245 |
| **PCA (256)** | 256 | **92.78** â­ | **92.86** | **92.78** | **92.78** | 26.62 | 0.0349 |
| **Rotation** | 784 | 81.05 | 81.53 | 81.05 | 80.85 | 54.21 | 0.0150 |

*Efficiency Ratio = Accuracy / (Features Ã— Training Time)

### Nháº­n xÃ©t:
- âœ… **PCA 256** Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t: **92.78%** (cao hÆ¡n baseline 0.71%)
- âœ… **Pooling 2Ã—2** cÃ³ efficiency ratio tá»‘t nháº¥t (giáº£m 75% features, váº«n giá»¯ 92.59% accuracy)
- âœ… **Sobel** vÃ  **Rotation** khÃ´ng hiá»‡u quáº£ (Ä‘á»™ chÃ­nh xÃ¡c tháº¥p hÆ¡n, thá»i gian huáº¥n luyá»‡n lÃ¢u hÆ¡n)
- âœ… **PCA** cÃ¢n báº±ng tá»‘t giá»¯a Ä‘á»™ chÃ­nh xÃ¡c, sá»‘ features, vÃ  thá»i gian huáº¥n luyá»‡n

### MÃ´ hÃ¬nh tá»‘t nháº¥t Ä‘Æ°á»£c chá»n:
ğŸ† **PCA 256 components** (saved in `models/best_model_weights.npz`)
- Accuracy: **92.78%**
- Explained Variance: **97.48%**
- Training Time: **26.62s**
- Features: **256** (giáº£m 67.3% so vá»›i baseline 784)

---

## ğŸ“š TÃ i liá»‡u Tham kháº£o

### Bá»™ dá»¯ liá»‡u:
- **MNIST Database**: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)
- KÃ­ch thÆ°á»›c: 60,000 training images + 10,000 test images
- Format: 28Ã—28 grayscale images (0-255)
- 10 classes: digits 0-9

### ThÆ° viá»‡n sá»­ dá»¥ng:
- [NumPy](https://numpy.org/) - TÃ­nh toÃ¡n khoa há»c
- [Matplotlib](https://matplotlib.org/) - Trá»±c quan hÃ³a
- [Streamlit](https://streamlit.io/) - á»¨ng dá»¥ng web
- [OpenCV](https://opencv.org/) - Xá»­ lÃ½ áº£nh
- [Seaborn](https://seaborn.pydata.org/) - Váº½ biá»ƒu Ä‘á»“ thá»‘ng kÃª

### TÃ i liá»‡u há»c thuáº­t:
- [Softmax Regression - CS229 Stanford](http://cs229.stanford.edu/notes/cs229-notes1.pdf)
- [PCA for Dimensionality Reduction](https://scikit-learn.org/stable/modules/decomposition.html#pca)
- [MNIST Handwritten Digit Classification](https://en.wikipedia.org/wiki/MNIST_database)

---

## âš ï¸ LÆ°u Ã½ vÃ  Xá»­ lÃ½ Lá»—i

### Lá»—i thÆ°á»ng gáº·p:

#### 1. **ModuleNotFoundError: No module named 'streamlit'**
**NguyÃªn nhÃ¢n**: ChÆ°a cÃ i Ä‘áº·t thÆ° viá»‡n hoáº·c cháº¡y sai Python environment  
**Giáº£i phÃ¡p**:
```bash
pip install -r requirements.txt
```
Hoáº·c activate virtual environment trÆ°á»›c:
```bash
.\venv\Scripts\Activate.ps1  # Windows
source venv/bin/activate      # Linux/Mac
```

#### 2. **FileNotFoundError: mnist.npz not found**
**NguyÃªn nhÃ¢n**: Dá»¯ liá»‡u MNIST chÆ°a Ä‘Æ°á»£c táº£i vá»  
**Giáº£i phÃ¡p**: Cháº¡y notebook láº§n Ä‘áº§u tiÃªn, hÃ m `load_mnist_data()` sáº½ tá»± Ä‘á»™ng táº£i vá» vÃ o `data/raw/`

#### 3. **Streamlit error: "Please run it as: streamlit run App_demo.py"**
**NguyÃªn nhÃ¢n**: Cháº¡y `python App_demo.py` thay vÃ¬ `streamlit run`  
**Giáº£i phÃ¡p**:
```bash
streamlit run App_demo.py
```

#### 4. **Lá»—i "port already in use"**
**NguyÃªn nhÃ¢n**: Port 8501 Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng  
**Giáº£i phÃ¡p**: Chá»‰ Ä‘á»‹nh port khÃ¡c:
```bash
streamlit run App_demo.py --server.port 8502
```

#### 5. **Notebook kernel crash khi cháº¡y PCA**
**NguyÃªn nhÃ¢n**: Thiáº¿u RAM (PCA vá»›i 60,000Ã—784 matrix tá»‘n ~300MB)  
**Giáº£i phÃ¡p**: Giáº£m sá»‘ samples hoáº·c tÄƒng RAM, hoáº·c cháº¡y trÃªn Google Colab

---

## ğŸ“ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n! Náº¿u báº¡n muá»‘n cáº£i thiá»‡n dá»± Ã¡n:
1. Fork repository
2. Táº¡o branch má»›i: `git checkout -b feature/your-feature`
3. Commit changes: `git commit -m "Add your feature"`
4. Push to branch: `git push origin feature/your-feature`
5. Táº¡o Pull Request

---

## ğŸ“§ LiÃªn há»‡

Náº¿u cÃ³ cÃ¢u há»i hoáº·c gÃ³p Ã½, vui lÃ²ng liÃªn há»‡ qua:
- Email: [email nhÃ³m]
- GitHub Issues: [Link to issues page]

---

**Cáº£m Æ¡n báº¡n Ä‘Ã£ xem dá»± Ã¡n! ğŸ‰**
